# This is the reusable workflow for the JS monitoring system.
# It contains the core four-job scanning pipeline and is triggered by workflow_call.
name: Reusable Scan Pipeline

on:
  workflow_call:
    inputs:
      environment_name:
        required: true
        type: string
    secrets:
      SESSION_COOKIE:
        required: false
      DISCORD_WEBHOOK_URL:
        required: false

jobs:
  # Job 1: Discover and filter live subdomains.
  discover-and-filter:
    name: "Scan (${{ inputs.environment_name }}): Discover & Filter"
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment_name }}
    outputs:
      live_hosts_found: ${{ steps.check_file.outputs.found }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'
      - name: Install Discovery Tools
        run: |
          go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
          go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
      - name: Discover and Filter Subdomains
        id: discover
        run: |
          subfinder -d "${{ vars.TARGET_DOMAIN }}" -silent | httpx -silent -status-code -mc 200,301,302,307 -o live_subdomains.txt
          echo "Found $(wc -l < live_subdomains.txt) live subdomains."
      - name: Check if live hosts were found
        id: check_file
        run: |
          if [ -s live_subdomains.txt ]; then
            echo "found=true" >> $GITHUB_OUTPUT
          else
            echo "found=false" >> $GITHUB_OUTPUT
            echo "No live subdomains found for ${{ vars.TARGET_DOMAIN }}. Stopping."
          fi
      - name: Upload live subdomains artifact
        if: steps.check_file.outputs.found == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: live-subdomains-${{ inputs.environment_name }}-${{ github.run_id }}
          path: live_subdomains.txt

  # Job 2: Generate a dynamic matrix for parallel processing.
  generate-matrix:
    name: "Scan (${{ inputs.environment_name }}): Generate Matrix"
    needs: discover-and-filter
    if: needs.discover-and-filter.outputs.live_hosts_found == 'true'
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment_name }}
    outputs:
      matrix: ${{ steps.split.outputs.matrix }}
    steps:
      - name: Download live subdomains artifact
        uses: actions/download-artifact@v4
        with:
          name: live-subdomains-${{ inputs.environment_name }}-${{ github.run_id }}
          path: .
      - name: Split subdomains into chunks
        id: split
        run: |
          mkdir -p chunks
          split -d -l 50 live_subdomains.txt chunks/chunk_
          MATRIX_JSON=$(ls -1q chunks/ | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "matrix=${MATRIX_JSON}" >> $GITHUB_OUTPUT
      - name: Upload subdomain chunks artifact
        uses: actions/upload-artifact@v4
        with:
          name: subdomain-chunks-${{ inputs.environment_name }}-${{ github.run_id }}
          path: chunks/

  # Job 3: Scan and Process in Parallel.
  scan-and-process:
    name: "Scan (${{ inputs.environment_name }}): Process Chunk ${{ matrix.chunk_file }}"
    needs: generate-matrix
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment_name }}
    strategy:
      fail-fast: false
      matrix:
        chunk_file: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Go & Node
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'
      - uses: actions/setup-node@v3
        with:
          node-version: '18'
      - name: Install Scanning Tools
        run: |
          go install -v github.com/projectdiscovery/katana/cmd/katana@latest
          go install -v github.com/lc/gau/v2/cmd/gau@latest
          npm install -g js-beautify
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
      - name: Download subdomain chunks artifact
        uses: actions/download-artifact@v4
        with:
          name: subdomain-chunks-${{ inputs.environment_name }}-${{ github.run_id }}
          path: chunks/
      - name: Discover and Process JS files (Debug Mode)
        env:
          SESSION_COOKIE: ${{ secrets.SESSION_COOKIE }}
        run: |
          CHUNK_FILE="chunks/${{ matrix.chunk_file }}"
          
          # DEBUG: Print the contents of the input file to ensure it's not empty.
          echo "--- DEBUG: Reading subdomains from ${CHUNK_FILE} ---"
          cat $CHUNK_FILE
          echo "----------------------------------------------------"

          KATANA_HEADER_ARGS=("-H" "User-Agent: Mozilla/5.0")
          if [ -n "$SESSION_COOKIE" ]; then KATANA_HEADER_ARGS+=("-H" "Cookie: $SESSION_COOKIE"); fi

          # Actively crawl the subdomains in this chunk for JS files.
          # NOTE: Removed '|| true' to ensure the step fails if Katana has an error.
          katana -list $CHUNK_FILE -jc -silent -d 5 -c 20 "${KATANA_HEADER_ARGS[@]}" -o katana-js.txt

          # Find historical JS files for the subdomains in this chunk.
          cat $CHUNK_FILE | gau --threads 5 | grep -iE '\.js$' | sort -u > gau-js.txt
          
          # DEBUG: Print the output of each tool.
          echo "--- DEBUG: Katana found $(wc -l < katana-js.txt) URLs ---"
          cat katana-js.txt
          echo "---------------------------------------------------------"
          
          echo "--- DEBUG: Gau found $(wc -l < gau-js.txt) URLs ---"
          cat gau-js.txt
          echo "---------------------------------------------------"
          
          # Combine results
          cat katana-js.txt gau-js.txt | sort -u > all_js_urls.txt

          # DEBUG: Print the final combined list and its size.
          echo "--- DEBUG: Total unique JS URLs found: $(wc -l < all_js_urls.txt) ---"
          cat all_js_urls.txt
          echo "------------------------------------------------------------------"

          # Now, call the original download script with the final list.
          # If 'all_js_urls.txt' is empty, the script will do nothing, which is expected.
          cat all_js_urls.txt | ./monitor.sh "${{ vars.TARGET_DOMAIN }}"

      - name: Upload Processed JS files
        if: success() # Only upload if the previous step succeeded.
        uses: actions/upload-artifact@v4
        with:
          name: js-files-batch-${{ inputs.environment_name }}-${{ matrix.chunk_file }}-${{ github.run_id }}
          path: js_files_temp/
          if-no-files-found: warn # Keep this to avoid errors if no files were downloaded


  # Job 4: Consolidate all results, commit changes, and notify.
  consolidate:
    name: "Scan (${{ inputs.environment_name }}): Consolidate & Notify"
    needs: scan-and-process
    if: always()
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment_name }}
    steps:
      - name: Checkout Full Git History
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Download All JS File Artifacts
        uses: actions/download-artifact@v4
        with:
          path: all_js_files/
          pattern: js-files-batch-${{ inputs.environment_name }}-*-${{ github.run_id }}
          #if-no-files-found: warn
      - name: Consolidate JS Files and Index
        run: |
          TARGET_DIR="js_files/${{ vars.TARGET_DOMAIN }}"
          mkdir -p "$TARGET_DIR"

          echo "Consolidating JS files and index maps..."
          if [ -d "all_js_files" ] && [ "$(ls -A all_js_files)" ]; then
            # Copy all downloaded JS files, preserving existing ones to avoid overwriting.
            find all_js_files -type f -name "*.js" -exec cp -n {} "$TARGET_DIR/" \;
            
            # Find all index.txt files, concatenate them into a temporary file.
            find all_js_files -type f -name "index.txt" -exec cat {} + >> "$TARGET_DIR/index.tmp"
            
            if [ -f "$TARGET_DIR/index.tmp" ]; then
              # Merge the new index entries with the existing master index file (if it exists),
              # then sort and unique the result to create a clean, comprehensive index.
              cat "$TARGET_DIR/index.tmp" "$TARGET_DIR/index.txt" 2>/null | sort -u > "$TARGET_DIR/index.final"
              mv "$TARGET_DIR/index.final" "$TARGET_DIR/index.txt"
              rm "$TARGET_DIR/index.tmp"
              echo "✅ Index files consolidated."
            fi
          else
            echo "No new files were downloaded by the scan jobs."
          fi
          echo "✅ Consolidation complete."
      - name: Detect and Commit Changes
        id: git_commit
        run: |
          TARGET_DIR="js_files/${{ vars.TARGET_DOMAIN }}"
          git config --global user.name "GitHub Action Bot"
          git config --global user.email "action-bot@github.com"
          git add -A "$TARGET_DIR/"
          if git diff --staged --quiet; then
            echo "changes_detected=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          git commit -m "[JS Scan] Update files for ${{ vars.TARGET_DOMAIN }}"
          git pull origin main --rebase
          git push origin main
          echo "changes_detected=true" >> $GITHUB_OUTPUT
          CHANGED_FILES=$(git diff --name-only HEAD^ HEAD -- "$TARGET_DIR/")
          echo "changed_files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
      - name: Analyze Changed Files
        if: steps.git_commit.outputs.changes_detected == 'true'
        run: |
          CHANGED_JS_FILES=$(echo "${{ steps.git_commit.outputs.changed_files }}" | grep '\.js$' || true)
          if [ -z "$CHANGED_JS_FILES" ]; then
            echo "✅ No changed JS files to analyze, only other file types (e.g., index.txt) were updated."
            exit 0
          fi
          
          echo "🐍 Setting up Python and installing analysis tools..."
          sudo apt-get update && sudo apt-get install -y python3-pip yara
          pip install git+https://github.com/m4ll0k/SecretFinder.git
          pip install git+https://github.com/GerbenJavado/LinkFinder.git
          chmod +x analyze_js.sh
          echo "🔬 Analyzing changed JS files:"
          echo "$CHANGED_JS_FILES"
          echo "$CHANGED_JS_FILES" | ./analyze_js.sh
      - name: Upload Analysis Results
        if: steps.git_commit.outputs.changes_detected == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results-${{ inputs.environment_name }}-${{ github.run_id }}
          path: analysis_results/
      - name: Send Notification on Change
        if: steps.git_commit.outputs.changes_detected == 'true'
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          TARGET_DOMAIN: ${{ vars.TARGET_DOMAIN }}
        run: |
          chmod +x send_notification.sh
          ./send_notification.sh
