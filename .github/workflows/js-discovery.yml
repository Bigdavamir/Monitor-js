# .github/workflows/js-discovery.yml
name: JS Discovery Pipeline (Multi-Stage Funnel)

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */12 * * *'

permissions:
  contents: write

jobs:
  # JAB 1: ÙÙ‚Ø· Ú©Ø´Ù ØºÛŒØ±ÙØ¹Ø§Ù„ URL Ù‡Ø§ÛŒ JS - Ø³Ø±ÛŒØ¹ Ùˆ Ø³Ø¨Ú©
  discover-passive-js:
    name: "1. Passive JS URL Discovery"
    runs-on: ubuntu-latest
    outputs:
      js_urls_found: ${{ steps.check_file.outputs.found }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'
      - name: Install Discovery Tools
        run: |
          go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
          go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
          go install -v github.com/projectdiscovery/katana/cmd/katana@latest
          go install -v github.com/tomnomnom/waybackurls@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
          
      - name: "Discover & Filter Static JS URLs"
        run: |
          # Stage 1: Get live subdomain seeds
          echo "INFO: Discovering live subdomains for ${{ vars.TARGET_DOMAIN }}..."
          subfinder -d "${{ vars.TARGET_DOMAIN }}" -silent | httpx -silent -mc 200,301,302,307 > live_subdomains.txt
          echo "INFO: Found $(wc -l < live_subdomains.txt) live subdomains."

          # Stage 2: Crawl for JS links using Katana
          echo "INFO: Using Katana to crawl for initial JS files..."
          # -jc: Javascript Crawl, -d 3: Crawl depth, -aff: Allow Foreign Files (for CDNs)
          katana -list live_subdomains.txt -jc -d 3 -aff -silent -o katana_urls.txt
          
          # Stage 3: Gather historical JS links from Wayback Machine
          echo "INFO: Using waybackurls to find historical JS files..."
          cat live_subdomains.txt | waybackurls > wayback_urls.txt

          # Stage 4: Combine, filter strictly for .js, strip parameters, and deduplicate
          echo "INFO: Combining, filtering, and deduplicating results..."
          cat katana_urls.txt wayback_urls.txt | grep -i '\.js' | sed 's/[?#].*//' | sort -u > discovered-js-urls.txt
          
          echo "SUCCESS: Discovered $(wc -l < discovered-js-urls.txt) unique potential JS URLs."

      - name: Check if JS URLs were found
        id: check_file
        run: |
          if [ -s discovered-js-urls.txt ]; then
            echo "found=true" >> $GITHUB_OUTPUT
          else
            echo "found=false" >> $GITHUB_OUTPUT
            echo "WARNING: No potential JS URLs found. Stopping workflow."
          fi
          
      - name: Upload Discovered JS URLs Artifact
        if: steps.check_file.outputs.found == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: discovered-js-urls
          path: discovered-js-urls.txt

  # JAB 2: Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒØŒ Ù‡Ø´â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ - Ø§ÛŒÙ† Ø¬Ø§Ø¨ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø³Ù†Ú¯ÛŒÙ† Ø¨Ø§Ø´Ø¯
  validate-and-hash:
    name: "2. Validate, Hash & Find New JS"
    runs-on: ubuntu-latest
    needs: discover-passive-js
    if: needs.discover-passive-js.outputs.js_urls_found == 'true'
    outputs:
      new_files_found: ${{ steps.find_new.outputs.found }}
    steps:
      - name: Checkout Full Git History
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download discovered JS URLs
        uses: actions/download-artifact@v4
        with:
          name: discovered-js-urls
          
      - name: Install Httpx
        run: |
          go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Validate JS URLs are live
        id: validate
        run: |
          echo "INFO: Validating $(wc -l < discovered-js-urls.txt) URLs..."
          # Only keep URLs that return 200 OK and have a javascript content-type
          httpx -list discovered-js-urls.txt -silent -mc 200 -ct -match-string "javascript" -o live-js-urls.txt
          echo "INFO: Found $(wc -l < live-js-urls.txt) live and valid JS files."
      
      - name: Generate Hashes for Live JS Files
        id: generate_hashes
        run: |
          # This script will download each URL, calculate its SHA256 hash, and output a 'url,hash' CSV
          # We create the script on the fly to avoid repo clutter.
          cat << 'EOF' > generate_hashes.sh
          #!/bin/bash
          # Use aria2c for fast, parallel downloads
          aria2c -i "$1" -j 20 --dir=./downloads --continue=true --auto-file-renaming=false
          
          # Process downloaded files
          while IFS= read -r url; do
            filename=$(basename "$url")
            filepath="./downloads/$filename"
            if [ -f "$filepath" ]; then
              hash=$(sha256sum "$filepath" | awk '{print $1}')
              echo "$url,$hash"
            fi
          done < "$1" > current_hashes.csv
          EOF
          
          chmod +x generate_hashes.sh
          ./generate_hashes.sh live-js-urls.txt

      - name: Find New JS Files by Comparing Hashes
        id: find_new
        run: |
          TARGET_DIR="js_files/${{ vars.TARGET_DOMAIN }}"
          mkdir -p "$TARGET_DIR"
          KNOWN_HASHES_FILE="$TARGET_DIR/known_hashes.csv"
          touch "$KNOWN_HASHES_FILE"
          
          # Compare current hashes with known hashes to find new ones
          # `grep -F -v -f file1 file2` finds lines in file2 that are NOT in file1
          # We extract just the known hashes for comparison
          cut -d, -f2 "$KNOWN_HASHES_FILE" > known_hashes_only.txt
          grep -F -v -f known_hashes_only.txt current_hashes.csv > new_files.csv
          
          if [ -s new_files.csv ]; then
            echo "found=true" >> $GITHUB_OUTPUT
            echo "SUCCESS: Found $(wc -l < new_files.csv) new JS files."
          else
            echo "found=false" >> $GITHUB_OUTPUT
            echo "INFO: No new JS files detected in this run."
          fi

      - name: Upload New JS Files Info
        if: steps.find_new.outputs.found == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: new-js-files
          path: new_files.csv

  # JAB 3: ØªØ­Ù„ÛŒÙ„ØŒ Ú©Ø§Ù…ÛŒØª Ùˆ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ - ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
  analyze-and-commit:
    name: "3. Analyze, Commit & Notify"
    runs-on: ubuntu-latest
    needs: validate-and-hash
    if: needs.validate-and-hash.outputs.new_files_found == 'true'
    steps:
      - name: Checkout Full Git History
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Download New JS Files Info
        uses: actions/download-artifact@v4
        with:
          name: new-js-files

      - name: Update Known Hashes and Prepare Summary
        id: process_commit
        run: |
          TARGET_DIR="js_files/${{ vars.TARGET_DOMAIN }}"
          KNOWN_HASHES_FILE="$TARGET_DIR/known_hashes.csv"
          
          # Append new files to the master list
          cat new_files.csv >> "$KNOWN_HASHES_FILE"
          
          # Create a summary for notification
          SUMMARY_CONTENT=$(awk -F, '{print "âœ… " $1}' new_files.csv)
          echo "summary<<EOF" >> $GITHUB_OUTPUT
          echo -e "$SUMMARY_CONTENT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Commit Changes
        run: |
          git config --global user.name "GitHub Action Bot"
          git config --global user.email "action-bot@github.com"
          TARGET_DIR="js_files/${{ vars.TARGET_DOMAIN }}"
          sort -u -o "$TARGET_DIR/known_hashes.csv" "$TARGET_DIR/known_hashes.csv"
          git add "$TARGET_DIR/known_hashes.csv"
          git commit -m "JS Scan: Discovered new files for ${{ vars.TARGET_DOMAIN }}"
          git pull origin main --rebase && git push --atomic origin main

      - name: Send Notification on Change
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          SUMMARY_CONTENT: ${{ steps.process_commit.outputs.summary }}
        run: |
          if [ -n "$DISCORD_WEBHOOK_URL" ]; then
            curl -X POST -H "Content-Type: application/json" \
            -d "{\"content\": \"ðŸ”Ž **New JavaScript URLs Detected for `${{ vars.TARGET_DOMAIN }}`**\n\`\`\`\n${SUMMARY_CONTENT}\n\`\`\`\"}" \
            "$DISCORD_WEBHOOK_URL"
          fi
