# Reusable JS Scan Pipeline - Optimized Single-Job Workflow (Advanced Deduplication)
name: Reusable Scan Pipeline (Single Target)

on:
  workflow_call:
    inputs:
      environment_name:
        required: true
        type: string
    secrets:
      SESSION_COOKIE:
        required: false
      DISCORD_WEBHOOK_URL:
        required: false

jobs:
  # This single job handles the entire process with clear, separate steps.
  scan-and-commit:
    name: "Scan, Consolidate & Notify (${{ inputs.environment_name }})"
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment_name }}
    steps:
      - name: Checkout Full Git History and Assets
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Required for git diff and for accessing filter files.

      - name: Set up Go, Node & System Tools
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'
      - uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install All Dependencies
        run: |
          echo "Installing system packages..."
          sudo apt-get update && sudo apt-get install -y python3-pip yara git jq

          echo "Installing Go and Node tools..."
          go install -v github.com/projectdiscovery/katana/cmd/katana@latest
          go install -v github.com/lc/gau/v2/cmd/gau@latest
          go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
          npm install -g js-beautify
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
          
          echo "Installing Python analysis tools..."
          pip install git+https://github.com/GerbenJavado/LinkFinder.git
          
          git clone https://github.com/m4ll0k/SecretFinder.git /opt/secretfinder
          pip install -r /opt/secretfinder/requirements.txt
          echo "/opt/secretfinder" >> $GITHUB_PATH
          echo "âœ… All dependencies installed."

      - name: Discover and Process JS Files (with Content Hashing)
        id: process_js
        env:
          SESSION_COOKIE: ${{ secrets.SESSION_COOKIE }}
        run: |
          echo "ðŸŽ¯ Starting scan for target: ${{ vars.TARGET_DOMAIN }}"
          echo "${{ vars.TARGET_DOMAIN }}" > target.txt

          # --- URL Discovery Phase ---
          katana -list target.txt -jc -silent -d 5 -c 25 -H "User-Agent: Mozilla/5.0" -o katana-out.txt || true
          cat target.txt | gau --threads 5 | grep -iE "^https?://(www\.)?${{ vars.TARGET_DOMAIN }}/" > gau-out.txt
          cat katana-out.txt gau-out.txt | sort -u > all_urls.txt
          
          grep -iE '\.js($|\?)' all_urls.txt > all_js_urls.txt
          grep -ivE '\.js($|\?)' all_urls.txt | httpx -silent -threads 25 -H "User-Agent: Mozilla/5.0" -json -o probed.json || true
          if [ -s probed.json ]; then
            jq -r 'select(.content_type != null and (.content_type | test("javascript|x-javascript"))) .url' probed.json >> all_js_urls.txt
          fi
          sort -u -o all_js_urls.txt all_js_urls.txt
          JS_COUNT=$(wc -l < all_js_urls.txt)
          echo "âœ… Found $JS_COUNT unique JS URLs. Proceeding to download and process."
          echo "js_url_count=$JS_COUNT" >> $GITHUB_OUTPUT

          # --- Advanced Processing Setup ---
          TEMP_DIR="js_files_temp"
          mkdir -p "$TEMP_DIR"
          
          WGET_ARGS="--user-agent=Mozilla/5.0 --quiet --no-check-certificate --tries=2 --timeout=20"
          if [ -n "$SESSION_COOKIE" ]; then WGET_ARGS="$WGET_ARGS --header=Cookie:$SESSION_COOKIE"; fi
          
          LIBS_IGNORE_FILE="libs-ignore.txt"
          LIBS_HASHES_FILE="libs_hashes.txt"

          # --- Core Processing Function (SHA256 Content-Based) ---
          process_url() {
            url="$1"
            [ -z "$url" ] && return
            
            # Layer 1 Filter: Ignore based on URL pattern from libs-ignore.txt
            if [ -f "$LIBS_IGNORE_FILE" ] && grep -qf "$LIBS_IGNORE_FILE" <<< "$url"; then return; fi

            TEMP_FILE=$(mktemp)
            if wget $WGET_ARGS -O "$TEMP_FILE" "$url" && [ -s "$TEMP_FILE" ]; then
              CONTENT_HASH=$(sha256sum "$TEMP_FILE" | awk '{print $1}')
              [ -z "$CONTENT_HASH" ] && { rm -f "$TEMP_FILE"; return; }
              
              # Layer 2 Filter: Ignore based on content hash from libs_hashes.txt
              if [ -f "$LIBS_HASHES_FILE" ] && grep -qF "$CONTENT_HASH" "$LIBS_HASHES_FILE"; then { rm -f "$TEMP_FILE"; return; }; fi

              FINAL_JS_PATH="$TEMP_DIR/${CONTENT_HASH}.js"
              
              # Deduplication: Only beautify and move if we haven't seen this content before.
              if [ ! -f "$FINAL_JS_PATH" ]; then
                js-beautify -r "$TEMP_FILE" &>/dev/null
                mv "$TEMP_FILE" "$FINAL_JS_PATH"
              else
                rm -f "$TEMP_FILE" # Content already exists, discard download.
              fi
              
              # Always record the URL-to-content mapping.
              echo "${CONTENT_HASH}.js,$url" >> "$TEMP_DIR/manifest.csv"
            else
              rm -f "$TEMP_FILE" # Cleanup failed or empty download.
            fi
          }
          export -f process_url; export WGET_ARGS; export TEMP_DIR; export LIBS_IGNORE_FILE; export LIBS_HASHES_FILE
          
          cat all_js_urls.txt | xargs -P 25 --no-run-if-empty -I {} bash -c 'process_url "$@"' _ {}

      - name: Consolidate JS Files and Manifest
        run: |
          TARGET_BASE_DIR="js_files/${{ vars.TARGET_DOMAIN }}"
          TARGET_FILES_DIR="$TARGET_BASE_DIR/files"
          TARGET_MANIFEST="$TARGET_BASE_DIR/manifest.csv"
          TEMP_DIR="js_files_temp"
          
          mkdir -p "$TARGET_FILES_DIR"

          echo "Consolidating downloaded files..."
          if [ ! -d "$TEMP_DIR" ] || [ -z "$(ls -A $TEMP_DIR)" ]; then
            echo "No new files were downloaded. Nothing to consolidate."
            exit 0
          fi
          
          # Copy new JS files, but do not overwrite existing ones. This is the core of deduplication.
          find "$TEMP_DIR" -type f -name "*.js" -exec cp -n {} "$TARGET_FILES_DIR/" \;

          # Smartly merge the new manifest with the existing master manifest.
          if [ -f "$TEMP_DIR/manifest.csv" ]; then
            # Combine new and old manifest, then sort and unique based on the URL (second column)
            # to prevent multiple entries for the same URL pointing to the same hash.
            cat "$TEMP_DIR/manifest.csv" "$TARGET_MANIFEST" 2>/dev/null | sort -u -t, -k2,2 > "${TARGET_MANIFEST}.final"
            mv "${TARGET_MANIFEST}.final" "$TARGET_MANIFEST"
            echo "âœ… Manifest file updated."
          fi
          
          rm -rf "$TEMP_DIR"
          echo "âœ… Consolidation complete."

      - name: Detect and Commit Changes
        id: git_commit
        run: |
          TARGET_BASE_DIR="js_files/${{ vars.TARGET_DOMAIN }}"
          git config --global user.name "GitHub Action Bot"
          git config --global user.email "action-bot@github.com"

          git add -A "$TARGET_BASE_DIR/"

          if git diff --staged --quiet; then
            echo "âœ… No changes detected in the repository. Workflow finished successfully."
            echo "changes_detected=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "ðŸ’¾ Changes detected. Committing to the repository."
          git commit -m "[JS Scan] Update files for ${{ vars.TARGET_DOMAIN }}"
          
          echo "ðŸ”„ Syncing with remote repository..."
          git pull origin main --rebase
          
          echo "â¬†ï¸ Pushing changes..."
          git push origin main
          
          echo "changes_detected=true" >> $GITHUB_OUTPUT
          
          CHANGED_FILES=$(git diff --name-only HEAD^ HEAD -- "$TARGET_BASE_DIR/")
          echo "changed_files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Analyze Changes and Send Notification
        if: steps.git_commit.outputs.changes_detected == 'true'
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          TARGET_DOMAIN: ${{ vars.TARGET_DOMAIN }}
        run: |
          CHANGED_FILES="${{ steps.git_commit.outputs.changed_files }}"
          
          CHANGED_JS_FILES=$(echo "$CHANGED_FILES" | grep '\.js$' || true)
          
          if [ -n "$CHANGED_JS_FILES" ]; then
            echo "ðŸ”¬ Analyzing changed JS files..."
            chmod +x analyze_js.sh
            echo "$CHANGED_JS_FILES" | ./analyze_js.sh
          else
            echo "âœ… No changed JS files to analyze, only manifest or other files were updated."
          fi

          echo "ðŸš€ Sending notification..."
          chmod +x send_notification.sh
          ./send_notification.sh
