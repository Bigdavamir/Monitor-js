# This is the reusable workflow for scanning a single target environment.
# It's called by the main controller workflow (monitor.yml).
name: Reusable JS Scan Pipeline

on:
  workflow_call:
    inputs:
      environment_name:
        description: 'The target environment name (e.g., atlassian-com)'
        required: true
        type: string
    secrets:
      SESSION_COOKIE:
        required: false
      DISCORD_WEBHOOK_URL:
        required: false

jobs:
  # Job 1: Discover all JS URLs for the target domain.
  discover_urls:
    runs-on: ubuntu-latest
    outputs:
      js_urls_file: js_urls.txt
      url_count: ${{ steps.count-urls.outputs.count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set Target Domain from Environment
        id: set-domain
        run: echo "target_domain=${{ inputs.environment_name }}" | sed 's/-com$/.com/' >> $GITHUB_OUTPUT

      - name: Install Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'

      - name: Install Discovery Tools
        run: |
          go install github.com/lc/gau/v2/cmd/gau@latest
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest
          echo "âœ… Tools installed."

      - name: Discover Subdomains and Fetch JS URLs
        id: discover
        run: |
          TARGET_DOMAIN="${{ steps.set-domain.outputs.target_domain }}"
          echo "ðŸš€ Starting discovery for: $TARGET_DOMAIN"
          
          # Use gau to get URLs, filter for JS files, remove duplicates, and check if they are alive with httpx
          gau --providers wayback,commoncrawl,otx,urlscan "$TARGET_DOMAIN" | grep -iE '\.js$' | sort -u | httpx -silent -mc 200 > js_urls.txt
          
          echo "âœ… JS URL discovery complete."

      - name: Count Discovered URLs
        id: count-urls
        run: |
          COUNT=$(wc -l < js_urls.txt)
          echo "Found $COUNT live JS URLs."
          echo "count=$COUNT" >> $GITHUB_OUTPUT

      - name: Upload JS URLs as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: discovered-js-urls
          path: js_urls.txt

  # Job 2: Process JS files in parallel using a dynamic matrix.
  process_js_files:
    needs: discover_urls
    if: needs.discover_urls.outputs.url_count > 0
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        chunk_id: [0, 1, 2, 3, 4] # Creates a static matrix of 5 parallel runners
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Discovered JS URLs
        uses: actions/download-artifact@v4
        with:
          name: discovered-js-urls

      - name: Install Dependencies
        run: |
          sudo apt-get update && sudo apt-get install -y xargs
          npm install -g js-beautify

      - name: Split URLs and Assign to Runner
        run: |
          # Split the file into 5 chunks and assign one to this runner based on matrix.chunk_id
          total_lines=$(wc -l < js_urls.txt)
          lines_per_chunk=$(( (total_lines + 4) / 5 )) # Ceiling division
          start_line=$(( ${{ matrix.chunk_id }} * lines_per_chunk + 1 ))
          
          # Extract the lines for this chunk
          tail -n +$start_line js_urls.txt | head -n $lines_per_chunk > my_chunk.txt
          echo "Runner ${{ matrix.chunk_id }} will process $(wc -l < my_chunk.txt) URLs."

      - name: Set Target Domain from Environment
        id: set-domain
        run: echo "target_domain=${{ inputs.environment_name }}" | sed 's/-com$/.com/' >> $GITHUB_OUTPUT

      - name: Download and Process JS Files
        env:
          SESSION_COOKIE: ${{ secrets.SESSION_COOKIE }}
          MATRIX_ID: ${{ matrix.chunk_id }}
        run: |
          chmod +x monitor.sh
          cat my_chunk.txt | ./monitor.sh "${{ steps.set-domain.outputs.target_domain }}"

      - name: Upload Processed JS Files and Index
        uses: actions/upload-artifact@v4
        with:
          name: processed-js-${{ matrix.chunk_id }}
          path: js_files_temp/** # <--- THIS IS THE FIX!

  # Job 3: Analyze changes and send notifications.
  analyze_and_notify:
    needs: process_js_files
    if: always() # Run this job even if processing fails, to report status.
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set Target Domain from Environment
        id: set-domain
        run: echo "target_domain=${{ inputs.environment_name }}" | sed 's/-com$/.com/' >> $GITHUB_OUTPUT

      - name: Download all processed JS artifacts
        uses: actions/download-artifact@v4
        with:
          path: all_artifacts/

      - name: Organize Downloaded Files
        id: organize
        run: |
          TARGET_DOMAIN="${{ steps.set-domain.outputs.target_domain }}"
          CURRENT_JS_DIR="all_artifacts/current_js"
          mkdir -p "$CURRENT_JS_DIR"
          
          # Consolidate all downloaded files and index files from each artifact chunk
          find all_artifacts/processed-js-* -type d -print0 | while IFS= read -r -d $'\0' dir; do
            if [ -d "$dir" ]; then
              find "$dir" -name "*.js" -exec mv {} "$CURRENT_JS_DIR" \;
              if [ -f "$dir/index.txt" ]; then
                cat "$dir/index.txt" >> "$CURRENT_JS_DIR/index.txt"
              fi
            fi
          done
          
          echo "âœ… All artifacts consolidated into $CURRENT_JS_DIR"
          echo "js_dir=$CURRENT_JS_DIR" >> $GITHUB_OUTPUT
          echo "target=$TARGET_DOMAIN" >> $GITHUB_OUTPUT
          
      - name: Analyze for Changes
        id: analyze
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          chmod +x analyze_js.sh
          ./analyze_js.sh ${{ steps.organize.outputs.target }} ${{ steps.organize.outputs.js_dir }}
