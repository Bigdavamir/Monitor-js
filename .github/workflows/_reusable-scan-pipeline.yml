# _reusable-scan-pipeline.yml
name: Reusable JS Scan Pipeline (Katana + httpx probe + SHA256 dedupe)

on:
  workflow_call:
    inputs:
      environment_name:
        description: 'The target environment name (e.g., atlassian-com)'
        required: true
        type: string
    secrets:
      SESSION_COOKIE:
        required: false
      DISCORD_WEBHOOK_URL:
        required: false

env:
  PARALLEL_WORKERS: 8
  MAX_DOWNLOADS_PER_CHUNK: 2000
  JS_PROBE_THREADS: 25
  DOWNLOAD_CONCURRENCY: 25

jobs:
  discover_urls:
    name: "Discover JS Candidates (${{ inputs.environment_name }})"
    runs-on: ubuntu-latest
    outputs:
      js_count: ${{ steps.count.outputs.count }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Normalize target
        id: set-domain
        run: |
          DOMAIN="${{ inputs.environment_name }}"
          TARGET_DOMAIN=$(echo "$DOMAIN" | sed 's/-com$/.com/')
          echo "target_domain=$TARGET_DOMAIN" >> $GITHUB_OUTPUT

      - name: Setup Go & Node
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'
      - uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Cache Go/Node/Pip
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ${{ env.GOPATH }}/pkg/mod
            ${{ env.GOPATH }}/bin
            ~/.npm
            ~/.cache/pip
          key: ${{ runner.os }}-tool-cache-v1

      - name: Install discovery tools
        run: |
          go install github.com/projectdiscovery/katana/cmd/katana@latest
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Run katana crawl (produce candidates)
        run: |
          TARGET="${{ steps.set-domain.outputs.target_domain }}"
          echo "$TARGET" > target.txt
          katana -list target.txt -jc -silent -d 3 -c 20 -H "User-Agent: Mozilla/5.0" -o katana-out.txt || true
          # Keep only same-domain candidates
          grep -iE "^https?://(www\.)?${{ steps.set-domain.outputs.target_domain }}/" katana-out.txt | sort -u > all_candidates.txt || true
          echo "katana produced $(wc -l < all_candidates.txt || true) candidates."

      - name: Probe candidates with httpx and extract JS URLs
        run: |
          if [ ! -s all_candidates.txt ]; then
            echo "count=0" >> $GITHUB_OUTPUT
            touch js_urls.txt
            exit 0
          fi

          cat all_candidates.txt | httpx -silent -threads ${{ env.JS_PROBE_THREADS }} -json -H "User-Agent: Mozilla/5.0" -o probed.json || true

          # Filter rules:
          # 1) content_type contains javascript
          # 2) OR content_length header exists and > 0
          # 3) OR URL ends with .js (fallback)
          jq -r '
            (.[] |
              select(
                ((.content_type // "") | test("javascript|x-javascript")) 
                or ((.content_length // "0") | tonumber > 0)
                or (.url | test("\\.js($|\\?)"; "i"))
              ).url
            )
          ' probed.json 2>/dev/null > probed_js_urls.txt || true

          # also include any candidate that explicitly ends with .js in case probe missed it
          grep -iE "\\.js($|\\?)" all_candidates.txt >> probed_js_urls.txt || true

          sort -u -o js_urls.txt probed_js_urls.txt || true
          COUNT=$(wc -l < js_urls.txt || echo 0)
          echo "Found $COUNT JS candidate URLs after httpx probe."
          echo "count=$COUNT" >> $GITHUB_OUTPUT

      - name: Upload discovered-js-urls artifact
        uses: actions/upload-artifact@v4
        with:
          name: discovered-js-urls
          path: js_urls.txt

  generate_matrix:
    name: "Generate chunks"
    needs: discover_urls
    if: needs.discover_urls.outputs.js_count != '0'
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.split.outputs.matrix }}
    steps:
      - name: Download discovered-js-urls
        uses: actions/download-artifact@v4
        with:
          name: discovered-js-urls
          path: .

      - name: Split into chunks
        id: split
        run: |
          PARALLEL=${{ env.PARALLEL_WORKERS }}
          mkdir -p chunks
          total_lines=$(wc -l < js_urls.txt || echo 0)
          if [ "$total_lines" -eq 0 ]; then
            echo "matrix=[]" >> $GITHUB_OUTPUT
            exit 0
          fi
          lines_per_chunk=$(( (total_lines + PARALLEL - 1) / PARALLEL ))
          split -d -l $lines_per_chunk js_urls.txt chunks/chunk_
          CHUNKS_JSON=$(ls -1 chunks/ | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "matrix=$CHUNKS_JSON" >> $GITHUB_OUTPUT

      - name: Upload chunk files
        uses: actions/upload-artifact@v4
        with:
          name: subdomain-chunks-${{ inputs.environment_name }}-${{ github.run_id }}
          path: chunks/

  process_chunk:
    name: "Process chunk ${{ matrix.chunk_file }}"
    needs: generate_matrix
    if: needs.generate_matrix.outputs.matrix != '[]'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        chunk_file: ${{ fromJson(needs.generate_matrix.outputs.matrix) }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Normalize target
        id: set-domain
        run: |
          DOMAIN="${{ inputs.environment_name }}"
          TARGET_DOMAIN=$(echo "$DOMAIN" | sed 's/-com$/.com/')
          echo "target_domain=$TARGET_DOMAIN" >> $GITHUB_OUTPUT

      - name: Cache and setup tools
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ${{ env.GOPATH }}/pkg/mod
            ${{ env.GOPATH }}/bin
            ~/.npm
            ~/.cache/pip
          key: ${{ runner.os }}-tool-cache-v1

      - name: Setup Go & Node
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'
      - uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install runtime tools
        run: |
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest
          npm install -g js-beautify || true
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Download chunk
        uses: actions/download-artifact@v4
        with:
          name: subdomain-chunks-${{ inputs.environment_name }}-${{ github.run_id }}
          path: chunks/

      - name: Prepare chunk file
        run: |
          CHUNK="chunks/${{ matrix.chunk_file }}"
          if [ ! -f "$CHUNK" ]; then
            echo "Chunk not found."
            exit 0
          fi
          mkdir -p js_files_temp/runner_${{ matrix.chunk_file }}
          cp "$CHUNK" js_files_temp/runner_${{ matrix.chunk_file }}/my_chunk.txt
          echo "Runner has $(wc -l < js_files_temp/runner_${{ matrix.chunk_file }}/my_chunk.txt) URLs."

      - name: Download and process (probe used earlier; download only filtered URLs)
        env:
          SESSION_COOKIE: ${{ secrets.SESSION_COOKIE }}
        run: |
          set -euo pipefail
          RUNNER_DIR="js_files_temp/runner_${{ matrix.chunk_file }}"
          ALL_URLS="$RUNNER_DIR/my_chunk.txt"
          WGET_ARGS="--user-agent=Mozilla/5.0 --quiet --no-check-certificate --tries=2 --timeout=20"
          if [ -n "${SESSION_COOKIE:-}" ]; then WGET_ARGS="$WGET_ARGS --header=Cookie:${SESSION_COOKIE}"; fi
          LIBS_IGNORE="libs-ignore.txt"
          LIBS_HASHES="libs_hashes.txt"

          process_url() {
            url="$1"
            [ -z "$url" ] && return
            if [ -f "$LIBS_IGNORE" ] && grep -qf "$LIBS_IGNORE" <<< "$url"; then
              return
            fi

            tmpf=$(mktemp)
            if wget $WGET_ARGS -O "$tmpf" "$url"; then
              if [ ! -s "$tmpf" ]; then
                rm -f "$tmpf"
                return
              fi
              content_hash=$(sha256sum "$tmpf" | awk '{print $1}')
              if [ -z "$content_hash" ]; then
                rm -f "$tmpf"
                return
              fi
              if [ -f "$LIBS_HASHES" ] && grep -qF "$content_hash" "$LIBS_HASHES"; then
                rm -f "$tmpf"
                return
              fi
              final="$RUNNER_DIR/${content_hash}.js"
              if [ ! -f "$final" ]; then
                js-beautify -r "$tmpf" &>/dev/null || true
                mv "$tmpf" "$final"
              else
                rm -f "$tmpf"
              fi
              echo "${content_hash}.js,$url" >> "$RUNNER_DIR/manifest.csv" || true
            else
              rm -f "$tmpf"
            fi
          }
          export -f process_url
          export WGET_ARGS
          export LIBS_IGNORE
          export LIBS_HASHES

          head -n ${{ env.MAX_DOWNLOADS_PER_CHUNK }} "$ALL_URLS" > "$RUNNER_DIR/to_process.txt"
          cat "$RUNNER_DIR/to_process.txt" | xargs -P ${{ env.DOWNLOAD_CONCURRENCY }} --no-run-if-empty -I {} bash -c 'process_url "$@"' _ {}

      - name: Upload processed artifact
        uses: actions/upload-artifact@v4
        with:
          name: processed-js-${{ inputs.environment_name }}-${{ matrix.chunk_file }}-${{ github.run_id }}
          path: js_files_temp/runner_${{ matrix.chunk_file }}/

  consolidate_and_commit:
    name: "Consolidate & Commit (${{ inputs.environment_name }})"
    needs: process_chunk
    runs-on: ubuntu-latest
    steps:
      - name: Checkout full repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Normalize target
        id: set-domain
        run: |
          DOMAIN="${{ inputs.environment_name }}"
          TARGET_DOMAIN=$(echo "$DOMAIN" | sed 's/-com$/.com/')
          echo "target_domain=$TARGET_DOMAIN" >> $GITHUB_OUTPUT

      - name: Download all processed artifacts
        uses: actions/download-artifact@v4
        with:
          path: all_artifacts/
          if-no-files-found: warn

      - name: Consolidate files, manifests, and add README
        run: |
          TARGET_BASE="js_files/${{ steps.set-domain.outputs.target_domain }}"
          TARGET_FILES="$TARGET_BASE/files"
          TARGET_MANIFEST="$TARGET_BASE/manifest.csv"
          mkdir -p "$TARGET_FILES"
          TMP_MAN="all_artifacts/merged_manifest.tmp"

          find all_artifacts/ -type f -name "*.js" -exec cp -n {} "$TARGET_FILES/" \; || true
          find all_artifacts/ -type f -name "manifest.csv" -exec cat {} + >> "$TMP_MAN" || true

          if [ -f "$TMP_MAN" ]; then
            touch "$TARGET_MANIFEST"
            cat "$TMP_MAN" "$TARGET_MANIFEST" | sort -u -t, -k2,2 > "${TARGET_MANIFEST}.final" || true
            mv "${TARGET_MANIFEST}.final" "$TARGET_MANIFEST"
            rm -f "$TMP_MAN"
            echo "Manifest consolidated: $(wc -l < $TARGET_MANIFEST || true)"
          else
            echo "No new manifest entries."
          fi

          # Write a README that shows how to lookup URL by hash
          README="$TARGET_BASE/README_MANIFEST.md"
          {
            echo 'README - JS manifest lookup'
            echo '------------------------------------'
            echo 'This manifest maps content-hash filenames to original URLs in CSV format:'
            echo '<hash>.js,<original_url>'
            echo ''
            echo 'To find the original URL for a given changed JS file (example: 9f2a....js):'
            echo "grep '^9f2a' manifest.csv"
            echo ''
            echo 'To find by full filename:'
            echo "grep '9f2a...' manifest.csv"
            echo ''
            echo 'To show only the URL column for a specific hash:'
            echo "grep '^9f2a' manifest.csv | cut -d',' -f2-"
          } > "$README"

      - name: Commit changes
        id: git_commit
        run: |
          TARGET_BASE="js_files/${{ steps.set-domain.outputs.target_domain }}"
          git config --global user.name "GitHub Action Bot"
          git config --global user.email "action-bot@github.com"
          git add -A "$TARGET_BASE/"
          if git diff --staged --quiet; then
            echo "changes_detected=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          git commit -m "[JS Scan] Update files for ${{ steps.set-domain.outputs.target_domain }}" || true
          git pull origin main --rebase || true
          git push origin main || true
          echo "changes_detected=true" >> $GITHUB_OUTPUT
          CHANGED_FILES=$(git diff --name-only HEAD^ HEAD -- "$TARGET_BASE/" || true)
          echo "changed_files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Analyze & notify
        if: steps.git_commit.outputs.changes_detected == 'true'
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          TARGET_DOMAIN: ${{ steps.set-domain.outputs.target_domain }}
        run: |
          CHANGED_JS=$(echo "${{ steps.git_commit.outputs.changed_files }}" | grep '\.js$' || true)
          if [ -n "$CHANGED_JS" ]; then
            chmod +x analyze_js.sh || true
            echo "$CHANGED_JS" | ./analyze_js.sh || true
          fi
          chmod +x send_notification.sh || true
          ./send_notification.sh || true
