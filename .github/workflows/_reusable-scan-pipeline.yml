# _reusable-scan-pipeline.yml
name: Reusable JS Scan Pipeline (Subfinder + Gau + Katana + SHA256 dedupe)

on:
  workflow_call:
    inputs:
      environment_name:
        description: 'The target environment name (e.g., atlassian-com)'
        required: true
        type: string
    secrets:
      SESSION_COOKIE:
        required: false
      DISCORD_WEBHOOK_URL:
        required: false

env:
  PARALLEL_WORKERS: 8
  MAX_DOWNLOADS_PER_CHUNK: 2000
  JS_PROBE_THREADS: 25
  DOWNLOAD_CONCURRENCY: 25

jobs:
  discover_urls:
    name: "Discover JS Candidates (${{ inputs.environment_name }})"
    runs-on: ubuntu-latest
    outputs:
      js_count: ${{ steps.count.outputs.count }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Normalize target
        id: set-domain
        run: |
          DOMAIN="${{ inputs.environment_name }}"
          TARGET_DOMAIN=$(echo "$DOMAIN" | sed 's/-com$/.com/')
          echo "target_domain=$TARGET_DOMAIN" >> $GITHUB_OUTPUT

      - name: Setup Go & Node
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'
      - uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Cache Go/Node/Pip
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ${{ env.GOPATH }}/pkg/mod
            ${{ env.GOPATH }}/bin
            ~/.npm
            ~/.cache/pip
          key: ${{ runner.os }}-tool-cache-v1

      - name: Install discovery tools
        run: |
          go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
          go install -v github.com/lc/gau/v2/cmd/gau@latest
          go install -v github.com/projectdiscovery/katana/cmd/katana@latest
          go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Discover Subdomains and Fetch JS URLs
        id: count
        run: |
          TARGET_DOMAIN="${{ steps.set-domain.outputs.target_domain }}"
          echo "ðŸš€ Starting discovery for: $TARGET_DOMAIN"
          
          # Step 1: Find live subdomains
          echo "Finding live subdomains..."
          subfinder -d "$TARGET_DOMAIN" -silent | httpx -silent -status-code -mc 200,301,302,307 -o live_subdomains.txt
          echo "Found $(wc -l < live_subdomains.txt) live subdomains."

          # Step 2: Gather JS URLs from historical sources (gau) and active crawling (katana) in parallel
          echo "Gathering JS URLs from gau (historical) and katana (active)..."
          cat live_subdomains.txt | gau --threads 10 --providers wayback,commoncrawl,otx,urlscan | grep -iE '\.js($|\?)' > gau_js.txt &
          katana -list live_subdomains.txt -silent -jc -d 3 -c 25 -H "User-Agent: Mozilla/5.0" | grep -iE '\.js($|\?)' > katana_js.txt &
          wait # Wait for both background jobs to finish

          # Step 3: Combine, deduplicate, and perform the final, efficient probe on candidates
          echo "Combining, sorting, and probing candidate JS URLs..."
          cat gau_js.txt katana_js.txt | sort -u > candidate_js_urls.txt
          
          # This is the key part: only probe the .js files now to ensure they are live (200 OK)
          cat candidate_js_urls.txt | httpx -silent -mc 200 -threads ${{ env.JS_PROBE_THREADS }} > js_urls.txt

          # Step 4: Final count and output
          COUNT=$(wc -l < js_urls.txt)
          echo "âœ… Found $COUNT live and valid JS URLs."
          echo "count=$COUNT" >> $GITHUB_OUTPUT

      - name: Upload discovered-js-urls artifact
        uses: actions/upload-artifact@v4
        with:
          name: discovered-js-urls
          path: js_urls.txt

  generate_matrix:
    name: "Generate chunks"
    needs: discover_urls
    if: needs.discover_urls.outputs.js_count > 0
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.split.outputs.matrix }}
    steps:
      - name: Download discovered-js-urls
        uses: actions/download-artifact@v4
        with:
          name: discovered-js-urls
          path: .

      - name: Split into chunks
        id: split
        run: |
          PARALLEL=${{ env.PARALLEL_WORKERS }}
          mkdir -p chunks
          total_lines=$(wc -l < js_urls.txt)
          lines_per_chunk=$(( (total_lines + PARALLEL - 1) / PARALLEL ))
          split -d -l $lines_per_chunk js_urls.txt chunks/chunk_
          CHUNKS_JSON=$(ls -1 chunks/ | jq -R -s -c 'split("\n") | map(select(length > 0))')
          echo "matrix=$CHUNKS_JSON" >> $GITHUB_OUTPUT

      - name: Upload chunk files
        uses: actions/upload-artifact@v4
        with:
          name: subdomain-chunks-${{ inputs.environment_name }}-${{ github.run_id }}
          path: chunks/

  process_chunk:
    name: "Process chunk ${{ matrix.chunk_file }}"
    needs: generate_matrix
    if: needs.generate_matrix.outputs.matrix != '[]'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        chunk_file: ${{ fromJson(needs.generate_matrix.outputs.matrix) }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Cache and setup tools
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ${{ env.GOPATH }}/pkg/mod
            ${{ env.GOPATH }}/bin
            ~/.npm
            ~/.cache/pip
          key: ${{ runner.os }}-tool-cache-v1

      - name: Setup Go & Node
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'
      - uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install runtime tools
        run: |
          npm install -g js-beautify || true

      - name: Download chunk
        uses: actions/download-artifact@v4
        with:
          name: subdomain-chunks-${{ inputs.environment_name }}-${{ github.run_id }}
          path: chunks/

      - name: Prepare chunk file
        run: |
          CHUNK="chunks/${{ matrix.chunk_file }}"
          if [ ! -f "$CHUNK" ]; then
            echo "Chunk not found."
            exit 0
          fi
          mkdir -p js_files_temp/runner_${{ matrix.chunk_file }}
          cp "$CHUNK" js_files_temp/runner_${{ matrix.chunk_file }}/my_chunk.txt
          echo "Runner has $(wc -l < js_files_temp/runner_${{ matrix.chunk_file }}/my_chunk.txt) URLs."

      - name: Download and process URLs
        env:
          SESSION_COOKIE: ${{ secrets.SESSION_COOKIE }}
        run: |
          set -euo pipefail
          RUNNER_DIR="js_files_temp/runner_${{ matrix.chunk_file }}"
          ALL_URLS="$RUNNER_DIR/my_chunk.txt"
          WGET_ARGS="--user-agent=Mozilla/5.0 --quiet --no-check-certificate --tries=2 --timeout=20"
          if [ -n "${SESSION_COOKIE:-}" ]; then WGET_ARGS="$WGET_ARGS --header=Cookie:${SESSION_COOKIE}"; fi
          LIBS_IGNORE="libs-ignore.txt"
          LIBS_HASHES="libs_hashes.txt"

          process_url() {
            url="$1"
            [ -z "$url" ] && return
            # Layer 1 Filter: URL pattern matching
            if [ -f "$LIBS_IGNORE" ] && grep -qf "$LIBS_IGNORE" <<< "$url"; then
              return
            fi

            tmpf=$(mktemp)
            if wget $WGET_ARGS -O "$tmpf" "$url"; then
              if [ ! -s "$tmpf" ]; then
                rm -f "$tmpf"
                return
              fi
              content_hash=$(sha256sum "$tmpf" | awk '{print $1}')
              if [ -z "$content_hash" ]; then
                rm -f "$tmpf"
                return
              fi
              # Layer 2 Filter: Content hash matching
              if [ -f "$LIBS_HASHES" ] && grep -qF "$content_hash" "$LIBS_HASHES"; then
                rm -f "$tmpf"
                return
              fi
              final="$RUNNER_DIR/${content_hash}.js"
              # Only beautify and move if the file doesn't already exist
              if [ ! -f "$final" ]; then
                js-beautify -r "$tmpf" &>/dev/null || true
                mv "$tmpf" "$final"
              else
                rm -f "$tmpf"
              fi
              echo "${content_hash}.js,$url" >> "$RUNNER_DIR/manifest.csv"
            else
              rm -f "$tmpf"
            fi
          }
          export -f process_url WGET_ARGS LIBS_IGNORE LIBS_HASHES
          
          # Limit the number of downloads to prevent timeouts on huge targets
          head -n ${{ env.MAX_DOWNLOADS_PER_CHUNK }} "$ALL_URLS" > "$RUNNER_DIR/to_process.txt"
          cat "$RUNNER_DIR/to_process.txt" | xargs -P ${{ env.DOWNLOAD_CONCURRENCY }} --no-run-if-empty -I {} bash -c 'process_url "$@"' _ {}

      - name: Upload processed artifact
        uses: actions/upload-artifact@v4
        with:
          name: processed-js-${{ inputs.environment_name }}-${{ matrix.chunk_file }}-${{ github.run_id }}
          path: js_files_temp/runner_${{ matrix.chunk_file }}/

  consolidate_and_commit:
    name: "Consolidate & Commit (${{ inputs.environment_name }})"
    needs: process_chunk
    if: always() # Run even if process_chunk fails or is skipped
    runs-on: ubuntu-latest
    steps:
      - name: Checkout full repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Normalize target
        id: set-domain
        run: |
          DOMAIN="${{ inputs.environment_name }}"
          TARGET_DOMAIN=$(echo "$DOMAIN" | sed 's/-com$/.com/')
          echo "target_domain=$TARGET_DOMAIN" >> $GITHUB_OUTPUT

      - name: Download all processed artifacts
        uses: actions/download-artifact@v4
        with:
          path: all_artifacts/
          pattern: processed-js-${{ inputs.environment_name }}-*-${{ github.run_id }}
          if-no-files-found: warn

      - name: Consolidate files, manifests, and add README
        run: |
          TARGET_BASE="js_files/${{ steps.set-domain.outputs.target_domain }}"
          TARGET_FILES="$TARGET_BASE/files"
          TARGET_MANIFEST="$TARGET_BASE/manifest.csv"
          mkdir -p "$TARGET_FILES"
          TMP_MAN="all_artifacts/merged_manifest.tmp"

          find all_artifacts/ -type f -name "*.js" -exec cp -n {} "$TARGET_FILES/" \;
          find all_artifacts/ -type f -name "manifest.csv" -exec cat {} + >> "$TMP_MAN" || true

          if [ -f "$TMP_MAN" ]; then
            touch "$TARGET_MANIFEST"
            cat "$TMP_MAN" "$TARGET_MANIFEST" | sort -u -t, -k2,2 > "${TARGET_MANIFEST}.final"
            mv "${TARGET_MANIFEST}.final" "$TARGET_MANIFEST"
            rm -f "$TMP_MAN"
            echo "Manifest consolidated: $(wc -l < $TARGET_MANIFEST) entries."
          else
            echo "No new manifest entries found."
          fi

          README="$TARGET_BASE/README_MANIFEST.md"
          echo '# README - JS Manifest Lookup' > "$README"
          echo '------------------------------------' >> "$README"
          echo 'This manifest maps content-hash filenames to original URLs in CSV format:' >> "$README"
          echo '`<hash>.js,<original_url>`' >> "$README"
          echo '' >> "$README"
          echo 'To find the original URL for a given changed JS file (example: `9f2a....js`):' >> "$README"
          echo "
```bash" >> "$README"
echo "grep '^9f2a' manifest.csv" >> "$README"
echo "```" >> "$README"
          echo 'To show only the URL column for a specific hash:' >> "$README"
          echo "
```bash" >> "$README"
echo "grep '^9f2a' manifest.csv | cut -d',' -f2-" >> "$README"
echo "```" >> "$README"

      - name: Commit changes
        id: git_commit
        run: |
          TARGET_BASE="js_files/${{ steps.set-domain.outputs.target_domain }}"
          git config --global user.name "GitHub Action Bot"
          git config --global user.email "action-bot@github.com"
          git add -A "$TARGET_BASE/"
          if git diff --staged --quiet; then
            echo "No changes detected."
            echo "changes_detected=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          git commit -m "[JS Scan] Update files for ${{ steps.set-domain.outputs.target_domain }}"
          git pull origin main --rebase
          git push origin main
          echo "changes_detected=true" >> $GITHUB_OUTPUT
          CHANGED_FILES=$(git diff --name-only HEAD^ HEAD -- "$TARGET_BASE/")
          echo "changed_files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Analyze & notify
        if: steps.git_commit.outputs.changes_detected == 'true'
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          TARGET_DOMAIN: ${{ steps.set-domain.outputs.target_domain }}
        run: |
          CHANGED_JS=$(echo "${{ steps.git_commit.outputs.changed_files }}" | grep '\.js$' || true)
          if [ -n "$CHANGED_JS" ]; then
            if [ -f "analyze_js.sh" ]; then
              chmod +x analyze_js.sh
              echo "$CHANGED_JS" | ./analyze_js.sh
            fi
          fi
          if [ -f "send_notification.sh" ]; then
            chmod +x send_notification.sh
            ./send_notification.sh
          fi
